server:
  port: 8182

kafka-config:
  bootstrap-servers: localhost:19092, localhost:29092, localhost:39092
  schema-registry-url-key: schema.registry.url
  schema-registry-url: http://localhost:8081
  topic-name: twitter-topic
  topic-names-to-create:
    - twitter-topic

kafka-consumer-config:
  key-deserializer: org.apache.kafka.common.serialization.LongDeserializer
  value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
  consumer-group-id: twitter-topic-consumer
  auto-offset-reset: earliest
  specific-avro-reader-key: specific.avro.reader
  specific-avro-reader: true
  batch-listener: true
  # We will start listening explicitly after seeing the topic is already there.
  auto-startup: false
  # Concurrency set to the same as the number of partitions, for maximum concurrency and higher throughput.
  concurrency-level: 3
  # Duration to wait for a heartbeat before marking this consumer as dead.
  # It is recommended to wait for a few heartbeat cycles before marking a node as dead.
  session-timeout-ms: 10000
  heartbeat-interval-ms: 3000
  # If this amount of time is passed and there is not a poll happening,
  # coordinator will evict the consumer and trigger a re-balance.
  max-poll-interval-ms: 300000
  # Maximum number of records to fetch in each poll.
  max-poll-records: 500
  # Maximum bytes to fetch in each poll.
  max-partition-fetch-bytes-default: 1048576
  max-partition-fetch-bytes-boost-factor: 1
  # Duration we wait for one record from the poll. poll-timeout-ms being too high can cause CPU stall.
  poll-timeout-ms: 150

retry-config:
  initial-interval-ms: 1000
  max-interval-ms: 10000
  multiplier: 2.0
  maxAttempts: 3
  sleep-time-ms: 2000

elastic-config:
  index-name: twitter-index
  connection-url: http://localhost:9200
  connect-timeout-ms: 5000
  socket-timeout-ms: 30000
